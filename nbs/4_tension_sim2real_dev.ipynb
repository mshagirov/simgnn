{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Neural Network\n",
    "---\n",
    "> Graph neural network model for vertex dynamics and tension prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:43:54.449546Z",
     "start_time": "2021-08-19T05:43:54.418857Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T05:44:00.091479Z",
     "start_time": "2021-08-19T05:43:57.073791Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from os import path\n",
    "import datetime\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch_geometric.utils import to_networkx, from_networkx\n",
    "import networkx as nx\n",
    "from simgnn.datautils import load_array, load_graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10,10) # use larger for presentation\n",
    "matplotlib.rcParams['font.size']= 16 # use 14 for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T09:11:16.433399Z",
     "start_time": "2021-08-18T09:11:16.400192Z"
    }
   },
   "outputs": [],
   "source": [
    "from simgnn.datasets import persistence_loss, VertexDynamics, HaraMovies, HaraAblation\n",
    "from simgnn.transforms import Pos2Vec, ScaleVelocity, ScaleTension, ScalePressure, Reshape_x, TransformTension, RecoilAsTension\n",
    "# from torch_geometric.utils import to_undirected as T_undir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T09:07:06.579074Z",
     "start_time": "2021-08-18T09:07:06.545151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaults:\n",
      " |-device: cuda\n",
      " |-dtype : torch.float32\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "dtype = torch.float32\n",
    "print(f'Defaults:\\n |-device: {device}\\n |-dtype : {dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data, Stat-s, Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes for normalisation param-s:\n",
    "\n",
    "- Use `simgnn.transforms` to normalise real--Hara movies and ablation,  and simulated movies. Use same normalisation constants for all simulated movies.\n",
    "- For ablation movies, convert to  HaraMovies length scale (pixels) and use same `l_av` as for HaraMovies dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "|Dataset| Avg. edge len.|Tension/Recoil| Transforms (Normalisation)|Notes|\n",
    "|:---:|---:|---:|:---|:---:|\n",
    "|`single_distr_sims` | 1.08 a.u. | range=[0.00131, 4.26]; sd=0.637; median=0.305; mean=0.578; | `[Pos2Vec(scale=10*1.0)`, `ScaleVelocity(0.5*1.0)`, `ScaleTension(0.634,shift=0.6)]`| synthetic; w/o base tension |\n",
    "|`unimodal_wbasetens_sims` | 0.906 a.u. | range=[0.407, 5.47]; sd=0.729; median=1.48; mean=1.6| `[Pos2Vec(scale=10*1.0)`, `ScaleVelocity(0.5*1.0)`, `ScaleTension(0.634,shift=0.6)]`| synthetic; w/ non-zero base tension |\n",
    "|`HaraMovies`  | 26.32 pixels||`[Pos2Vec(scale=10*26.32)`, `ScaleVelocity(0.5*26.32)]`| tissue movies w/o force data|\n",
    "|`HaraAblation`|$26.32\\cdot\\frac{0.4}{0.21}$ pixels| range=[0.0239, 2.61]; sd=0.651; median=0.673; mean=0.826 | `[Pos2Vec(scale=10*50.13), ScaleVelocity(0.5*50.13)]`| short movies w/ recoil data; frame rate:dataset contains vertex positions only from every 10th frame |\n",
    "\n",
    "- Logarithm of tension: ln(Tension/Recoil {raw values})\n",
    "```\n",
    "Single_distr_sims:        range: [-6.63 1.45]; s.d.: 1.22 || median: -1.19; mean: -1.2;\n",
    "Unimodal_wbasetens_sims : range: [-0.9  1.7]; s.d.: 0.451 || median: 0.39; mean: 0.371;\n",
    "Hara ablation:            range: [-3.73 0.958]; s.d.:0.962 || median:-0.396; mean:-0.547;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **Normalisation param-s**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalisation param-s : sim=\"default\" for simulation data\n",
    "# Average edge lengths\n",
    "l_0 = {'sim':1.0, 'single_distr_sims':1.1, 'unimodal_wbasetens_sims':0.91, 'hara':26.32, 'abln':50.13}\n",
    "\n",
    "# Stat-s for raw tension/recoil values\n",
    "t_av = {'sim':0.6, 'single_distr_sims': 0.58, 'unimodal_wbasetens_sims': 1.6, 'abln': 0.83}\n",
    "t_sd = {'sim':0.63, 'single_distr_sims': 0.64, 'unimodal_wbasetens_sims':0.73 , 'abln': 0.65}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T09:07:20.046196Z",
     "start_time": "2021-08-18T09:07:19.447827Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm -dr simgnn_data/single_distr_sims/train/processed\n",
    "!rm -dr simgnn_data/single_distr_sims/val/processed\n",
    "!rm -dr simgnn_data/unimodal_wbasetens_sims/train/processed\n",
    "!rm -dr simgnn_data/unimodal_wbasetens_sims/val/processed\n",
    "\n",
    "!rm -dr simgnn_data/hara_movies/processed/\n",
    "!rm -dr simgnn_data/hara_ablation/processed/\n",
    "\n",
    "# !rm -dr simgnn_data/hara_movies_as_sep_datasets/hara_seg001/processed/\n",
    "# !rm -dr simgnn_data/hara_movies_as_sep_datasets/hara_seg003/processed/\n",
    "# !rm -dr simgnn_data/hara_movies_as_sep_datasets/hara_seg005/processed/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input features and normalisation param-s (transforms)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Set features window size (#past velocities) to 5\n"
     ]
    }
   ],
   "source": [
    "# Input features\n",
    "window_size = 5\n",
    "print(f'> Set features window size (#past velocities) to {window_size}')\n",
    "\n",
    "# Normalisation\n",
    "# for simulated data (simul params ~ normal distr-s): l0_sim=1.0, l0_HaraMovie: l0=26.32\n",
    "Tnrm = {} # dict of transforms\n",
    "\n",
    "# Default for all simulations:\n",
    "Tnrm['sim'] = T.Compose([Pos2Vec(scale=10*l_0['sim']) , ScaleVelocity(0.5*l_0['single_distr_sims']),\n",
    "                         ScaleTension(t_sd['sim'], shift=t_av['sim']),\n",
    "                         Reshape_x((-1,window_size*2)) ] )\n",
    "\n",
    "# w/o base contractility:\n",
    "Tnrm['single_distr_sims'] = T.Compose([Pos2Vec(scale=10*l_0['single_distr_sims']) , ScaleVelocity(0.5*l_0['single_distr_sims']),\n",
    "                                       ScaleTension(t_sd['single_distr_sims'], shift=t_av['single_distr_sims']),\n",
    "                                       Reshape_x((-1,window_size*2)) ] )\n",
    "\n",
    "# w/ base contractility:\n",
    "Tnrm['unimodal_wbasetens_sims'] = T.Compose([Pos2Vec(scale=10*l_0['unimodal_wbasetens_sims']) , ScaleVelocity(0.5*l_0['unimodal_wbasetens_sims']),\n",
    "                                             ScaleTension(t_sd['unimodal_wbasetens_sims'], shift=t_av['unimodal_wbasetens_sims']),\n",
    "                                             Reshape_x((-1,window_size*2)) ] )\n",
    "\n",
    "# Hara ablation norm\n",
    "Tnrm['abln'] = T.Compose([Pos2Vec(scale=10*l_0['abln']), ScaleVelocity(0.5*l_0['abln']), RecoilAsTension(),\n",
    "                          ScaleTension(t_sd['abln'], shift=t_av['abln']),\n",
    "                          Reshape_x((-1,window_size*2))]) \n",
    "\n",
    "# Hara movie dataset norm\n",
    "Tnrm['hara'] = T.Compose([Pos2Vec(scale=10*l_0['hara']) , ScaleVelocity(0.5*l_0['hara']), Reshape_x((-1,window_size*2))]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T09:15:56.262624Z",
     "start_time": "2021-08-18T09:15:56.206267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "hara_abln = HaraAblation('simgnn_data/hara_ablation/', window_size=window_size, transform=Tnrm['abln'], smoothing=True, sma_lag_time=3)\n",
    "hara = HaraMovies('simgnn_data/hara_movies/',window_size=window_size, transform=Tnrm['hara'], smoothing=True, sma_lag_time=4)\n",
    "\n",
    "# Hara movie datasets\n",
    "# seg001 = HaraMovies('simgnn_data/hara_movies_as_sep_datasets/hara_seg001/', window_size=window_size, transform=Tnorm_hara,smoothing=True, sma_lag_time=4)\n",
    "# seg001_raw = HaraMovies('simgnn_data/hara_movies/', window_size=window_size, transform=Tnorm_hara)\n",
    "# seg003 = HaraMovies('simgnn_data/hara_movies_as_sep_datasets/hara_seg003/', window_size=window_size, transform=Tnorm_hara,smoothing=True, sma_lag_time=4)\n",
    "# seg005 = HaraMovies('simgnn_data/hara_movies_as_sep_datasets/hara_seg005/', window_size=window_size, transform=Tnorm_hara,smoothing=True, sma_lag_time=4)\n",
    "\n",
    "# Simulation datasets\n",
    "# rand base contractility\n",
    "sim1 = VertexDynamics('./simgnn_data/unimodal_wbasetens_sims/train/', window_size=window_size,\n",
    "                      transform=Tnrm['unimodal_wbasetens_sims']\n",
    "                     )\n",
    "sim1_val = VertexDynamics('./simgnn_data/unimodal_wbasetens_sims/val/', window_size=window_size,\n",
    "                          transform=Tnrm['unimodal_wbasetens_sims']\n",
    "                         )\n",
    "\n",
    "# w/o base contractility\n",
    "sim2 = VertexDynamics('./simgnn_data/single_distr_sims/train/', window_size=window_size,\n",
    "                      transform=Tnrm['single_distr_sims'])\n",
    "sim2_val = VertexDynamics('./simgnn_data/single_distr_sims/val/', window_size=window_size,\n",
    "                          transform=Tnrm['single_distr_sims']\n",
    "                         )\n",
    "\n",
    "\n",
    "datasets_dict = {'train': sim1,\n",
    "                 'val': sim1_val,\n",
    "                 'val2': sim2_val,\n",
    "                 'hara' : hara,\n",
    "                 'abln': hara_abln}\n",
    "dataset_legend={'train': 'Train(sim1)',\n",
    "                'val': 'Val(sim1)',\n",
    "                'val2': 'Val(sim2)',\n",
    "                'hara': 'Hara',\n",
    "                'abln': 'Recoil'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T20:39:10.846237Z",
     "start_time": "2021-05-28T20:39:08.262162Z"
    }
   },
   "outputs": [],
   "source": [
    "# k='val2'\n",
    "# print('{}\\n{} : {}\\nsize:{}\\n\\nFrame 1:\\n{}'.format(dataset_legend[k],k,datasets_dict[k],len(datasets_dict[k]),datasets_dict[k][0]))\n",
    "# plt.figure(figsize=[2.5,2.5])\n",
    "# nx.draw(to_networkx(datasets_dict[k][0]),pos=dict(enumerate(datasets_dict[k][0].pos.numpy())), node_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Persistence Losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T20:39:12.928388Z",
     "start_time": "2021-05-28T20:39:10.849266Z"
    }
   },
   "outputs": [],
   "source": [
    "# print('Persistence:')\n",
    "# for k in datasets_dict:\n",
    "#     if k=='abln':print('Ignoring ablation data velocity');continue\n",
    "#     print(f'\\t- {dataset_legend[k]}: {persistence_loss(datasets_dict[k])}')\n",
    "    \n",
    "# print(len(datasets_dict['train']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do**👷🚧\n",
    "- need a func-n w/ a **rollout error**,\n",
    "- convert vel-y error to **position error**, e.g. \"speed\"+\"direction\"(angle/dot product etc.)\n",
    "- *Training loop*:\n",
    "    - [ ] Combine `Message` and `AggregateUpdate` into a graph layer `GraphBlock`\n",
    "- [ ] Write *prediction stage*: read \\{test, val, train\\} data for rollout error measurements.\n",
    "- [ ] Experiments (**save all models** w/ backups; will need to test on the real tensions)<br>\n",
    "*Params*: edge attrib-s, cell layer, arch(skip con-s), input noise (for long term prediction). *Errors*: 1-step, and rollout error (check after training at test time).\n",
    "    1. Experiment with GN arch-s w/ *residual* (w/ skip) and *non-residual* architectures.\n",
    "    1. *Edge directions experiment*: train w/ and w/o edge dir-s, do edge dir-s help to speed up training?\n",
    "    1. *Cell layer*: does having dedicated cell processing layer help to increase the accuracy?\n",
    "    1. For best (resnet or non-resnet) run *number of layers and dim-n sizes*. Try deep nets, how does accuracy change with increasing the depth of the net?\n",
    "    1. If resnet is better: try w/and w/o edge dir-s and \"cell layers\".\n",
    "    1. Number of previous velocities (window size).\n",
    "    1. Rollout experiment 1— *input noise*: according to Sanchez-Gonzalez, *et al.* \\[ASG2020\\], Brownian noise improves rollout accuracies (long term accuracy of the whole movie, and/or prediction stability/robustness).\n",
    "    1. Rollout experiment 2— *rollout training*: train directly on rollout, i.e. use 5- and 10-step loss instead of a 1-step loss for training (slower training).\n",
    "    1. Optional:\n",
    "        - compare MLP vs CONV layers for message passing.\n",
    "        - try with dynamic graphs (construct graphs on the fly based on relative positions, and use cell edges and cell attrib only for queries on `Y_edge`, `Y_cell`).\n",
    "- [ ] Ablation dataset (*real*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**DOING**🛠\n",
    "1. Construct graph net without skip connections.\n",
    "1. Combine Message and AggregateUpdate into a graph layer GraphNet (GN) block, a more general block, that can be composed into a deep residual network. \"AddGN\" block, w/ `AddGN(x) = f(x)+x` form (in fact, where it's possible make all blocks with this form.\n",
    "1. Construct residual net out of GNs.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Examples**:\n",
    "    - General \"Message Passing\" schemes: a nice example for composite graph layer –\"meta layer\" consisting of \"edge\", \"node\" and \"global\" layers [link](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.meta.MetaLayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Node-to-Cell Encoding/Pooling Layer**:\n",
    "1. Initiate node-to-cell edge attr-s as (source) node attr-s `x[node2cell_index[0]]`.\n",
    "1. Compute node-to-cell edge attr-s using MLP: `e_n2c = MLP( x[node2cell_index[0]] )`\n",
    "1. Aggregate node-to-cell edge attr-s as cell attr-s : `x_cell = Aggregate(e_n2c)`\n",
    "1. Compute new cell attr-s using (encodes `x_cell` into cell attr-s) : `h_cell = MLP_Cell_encoder( x_cell )`\n",
    "\n",
    "```python\n",
    "n2c_model = mlp(...) # \"message\", just node-wise MLP\n",
    "cell_aggr = Aggregate()\n",
    "cell_enc = mlp(...)\n",
    "\n",
    "e_n2c = n2c_model(data.x)[data.node2cell_index[0]]\n",
    "x_cell = cell_aggr(data.cell_pressures.size(0), data.node2cell_index, e_n2c)\n",
    "h_cell = cell_enc(x_cell)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **Adding noise from M steps**: Sum of M normal rand. var-s results in normal var. w/ variance M and s.t.d.=sqrt(M):\n",
    "```python\n",
    "x = np.random.normal(size=(5,1000))\n",
    "y = x.sum(axis=0)\n",
    "z = np.random.normal(size=(1,1000))*np.sqrt(5)\n",
    "plt.hist(x.ravel(),bins=50,label='x',density=True)\n",
    "plt.hist(y        ,bins=50,label='y',density=True)\n",
    "plt.hist(z.ravel(),bins=50,label='z',density=True,alpha=.5)\n",
    "plt.legend();\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tension Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simgnn.train import train_model, write_log, load_log, plot_losses\n",
    "from simgnn.train import predict, predict_batch, plot_velocity_predictions, plot_tension_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simgnn.nn import mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need\n",
    "- Enc\n",
    "- Dec\n",
    "- Block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndependentEncoder (torch.nn.Module):\n",
    "    '''\n",
    "    Layer for encoding node and edge features using independent MLPs.\n",
    "    \n",
    "    The last layer is always a plain linear layer, i.e. it has no dropout/activation.\n",
    "    '''\n",
    "    def __init__(self, in_dims, latent_dim, hidden_dims=[],mlp_kwargs={}):\n",
    "        '''\n",
    "        Arg-s:\n",
    "            - in_dims : number of input dimensions. A dict of integers w/ keys \"node\" and \"edge\".\n",
    "            - latent_dim : number of output dimensions for encoder MLPs.\n",
    "            - hidden_dims : a list of hidden dimensions.\n",
    "        \n",
    "        Note:\n",
    "            - The same `latent_dim`, `hidden_dims`, and `mlp_kwargs` arg-s are used for both edge and node MLPs.\n",
    "        '''\n",
    "        super(IndependentEncoder, self).__init__()\n",
    "        self.node_mlp = mlp(in_dims['node'],latent_dim, hidden_dims=hidden_dims,**mlp_kwargs)\n",
    "        self.edge_mlp = mlp(in_dims['edge'],latent_dim, hidden_dims=hidden_dims,**mlp_kwargs)\n",
    "        \n",
    "    def forward(self, x, e):\n",
    "        return self.node_mlp(x), self.edge_mlp(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CellData(cell2node_index=[2, 38], edge_attr=[29, 2], edge_index=[2, 29], edge_recoils=[29], edge_tensions=[29], node2cell_index=[2, 38], pos=[24, 2], x=[24, 10])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hara_abln[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Enc = IndependentEncoder({'node':10,'edge':2}, 16, hidden_dims=[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_e, e_e = Enc(hara_abln[0].x,hara_abln[0].edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T17:39:24.417001Z",
     "start_time": "2021-05-24T17:39:24.381305Z"
    }
   },
   "outputs": [],
   "source": [
    "class SingleMP_Tension(torch.nn.Module):\n",
    "    '''\n",
    "    Returns tuple (y_pred, None, None):\n",
    "    - y_pred: is a node-wise output (e.g. node velocity)\n",
    "    - The two `None`s are just place holders to make model compatible with training function in `train.py`.\n",
    "    '''\n",
    "    def __init__(self, node_in_features=10, node_out_features=2, edge_in_features=2,\n",
    "                 message_out_features=5, message_hidden_dims=[10], update_hidden_dims = [],aggr='mean',\n",
    "                 tension_out_features=1, tension_hidden_dims=[5], **mlp_kwargs):\n",
    "        '''\n",
    "        Arg-s:\n",
    "        - node_in_features : #input node features\n",
    "        - node_out_features: #output node features\n",
    "        - edge_in_features : #input edge features\n",
    "        - message_out_features : #message features (edge-wise messages, can be considered as new or intermediate edge features )\n",
    "        - message_hidden_dims : list of #dims for message MLP=phi. For edge s->t: m_st = phi([x_t - x_s, e_st]).\n",
    "        - update_hidden_dims : list of #dims for update MLP=gamma. For node i : x_i' = gamma(x_i, Aggregate(m_si))\n",
    "        - Optional kwargs for both MLPs: defaults are `dropout_p = 0`, `Fn = ReLU`, `Fn_kwargs = {}`.\n",
    "        '''\n",
    "        super(SingleMP_Tension, self).__init__()\n",
    "\n",
    "        self.message = DiffMessage(node_in_features+edge_in_features,\n",
    "                                   message_out_features,\n",
    "                                   hidden_dims=message_hidden_dims, **mlp_kwargs)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.aggr_update = AggregateUpdate(node_in_features+message_out_features,\n",
    "                                           node_out_features, hidden_dims=update_hidden_dims, aggr=aggr, **mlp_kwargs)\n",
    "        self.tension_mlp = mlp(message_out_features, tension_out_features, \n",
    "                               hidden_dims=tension_hidden_dims, **mlp_kwargs)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # convert to undirected graph : cat([e_ij, e_ji])\n",
    "        edge_index = torch.cat([ data.edge_index, torch.stack([data.edge_index[1],\n",
    "                                                               data.edge_index[0]], dim=0) ], dim=1).contiguous()\n",
    "        # edge features for undirected graph : e_ij = - e_ji\n",
    "        edge_attr  = torch.cat([ data.edge_attr, -data.edge_attr], dim=0).contiguous()\n",
    "\n",
    "        # message\n",
    "        src, tgt = data.x[edge_index[0]], data.x[edge_index[1]] # src, tgt features\n",
    "        m_ij = self.relu( self.message(src, tgt, edge_attr) )\n",
    "\n",
    "        # aggregate and update stages\n",
    "        x_out = self.aggr_update( data.x, edge_index, m_ij) # leave last layer as linear, i.e. no ReLU()\n",
    "        \n",
    "        # tension model\n",
    "        e_out = self.tension_mlp(m_ij[:m_ij.size(0)//2,:] +  m_ij[m_ij.size(0)//2 :,:])\n",
    "        \n",
    "        return x_out, e_out.reshape((e_out.size(0),)), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T17:42:34.089995Z",
     "start_time": "2021-05-24T17:39:24.602050Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "211.796875px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
