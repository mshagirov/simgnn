{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Dataset Loading and Batching\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from os import path\n",
    "\n",
    "import networkx as nx\n",
    "from simgnn.datautils import load_array, load_graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10,10) # use larger for presentation\n",
    "matplotlib.rcParams['font.size']= 14 # use 14 for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaults:\n",
      " |-device: cuda\n",
      " |-dtype : torch.float32\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "dtype = torch.float32\n",
    "print(f'Defaults:\\n |-device: {device}\\n |-dtype : {dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Need to implement*: `raw_i` $\\mapsto$ `Data()`$\\mapsto$ `Dataset.process()` $\\mapsto$`processed` dir (save processed graphs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '../../../dataDIR/simgnn_data/raw'# location of all datasets\n",
    "raw_path = path.join(data_root,'17Nov2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_dict.pkl\tsimul_Ka.npy\t     simul_Length.npy\t  simul_t.npy\n",
      "simul_A0.npy\tsimul_Kp.npy\t     simul_P0.npy\t  simul_vtxpos.npy\n",
      "simul_Area.npy\tsimul_Lambda_ij.npy  simul_Perimeter.npy  t_Energy_maxSpeed.npy\n"
     ]
    }
   ],
   "source": [
    "!ls $raw_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representation of cells in the monolayer graph:\n",
    "- dict of lists with cell numbers $0, 1, \\dots N$ as keys, and edges (values).\n",
    "- edge ind-s **start from 1** in the cells (values), don't forget to **convert** when indexing edges tensor (e.g. `edge_ID=np.abs(ID)-1`). Negative indices indicate reversed order for vertices (cell is defined as a closed region formed by edges connected *end-to-end*). Use `np.sign(cells[c])` to find reversed edges for cell `c`.\n",
    "    - e.g. get edges of cell `c` : `np.abs(mg_dict['cells'][c])-1` (`mg_dict` is monolayer graph dict loaded with `datautils.load_graph`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dict of monolayer graph\n",
    "mg_dict = load_graph(path.join(raw_path,'graph_dict.pkl'))\n",
    "\n",
    "# Load vertex positions from simulation results: Frames x Vertices x Positions\n",
    "vx_pos = load_array(path.join(raw_path,'simul_vtxpos.npy')) # T x N x 2\n",
    "vx_vel = np.diff(vx_pos,n=1,axis=0) # T-1 x N x 2\n",
    "\n",
    "# init-l vertex positions (1st frame)\n",
    "vx0 = vx_pos[0]\n",
    "\n",
    "# convert edges list to tensor\n",
    "edges = torch.tensor(mg_dict['edges'],dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_pos:(95, 240, 2) (T+0 pos-n)\n",
      "node_features:(95, 240, 5, 2) ([T-1:T-window_size] vel-s)\n",
      "- - - - - - -\n",
      "Y_node : (95, 240, 2) (T+0 vel-y)\n"
     ]
    }
   ],
   "source": [
    "window_size = 5\n",
    "Y_node = vx_vel[window_size:] # Vel[w:]\n",
    "node_pos = vx_pos[window_size:-1]\n",
    "\n",
    "# last_index = total_frames - (2+window_size)\n",
    "# num_of_features = last_index+1\n",
    "X_node = np.stack([ vx_vel[k:k+window_size].transpose((1,0,2))\n",
    "                    for k in range(vx_pos.shape[0]-(2+window_size)+1)])\n",
    "\n",
    "print(f'node_pos:{node_pos.shape} (T+0 pos-n)')\n",
    "print(f'node_features:{X_node.shape} ([T-1:T-window_size] vel-s)\\n-'+5*' -'+' -')\n",
    "print(f'Y_node : {Y_node.shape} (T+0 vel-y)')\n",
    "# node_pos[0] = vx_pos[window_size] ; node_pos[-1] = vx_pos[-2]\n",
    "# =>vx_pos[-1]=node_pos[-1]+Y_node[-1]\n",
    "# node_next = vx_pos[window_size+1:]\n",
    "# assert np.sum(np.abs(Y_node+node_pos-node_next)) == 0\n",
    "#\n",
    "# assert np.sum(np.abs(X_node[0][:,-1,:]-vx_vel[4])) ==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = 13\n",
    "# plt.quiver(vx_pos[t,:,0],vx_pos[t,:,1], vx_vel[t,:,0], vx_vel[t,:,1],units='xy',angles='xy',scale=.1)\n",
    "# plt.plot(vx_pos[t,:,0],vx_pos[t,:,1],'ro',alpha=.5)\n",
    "# plt.plot(vx_pos[t+1,:,0],vx_pos[t+1,:,1],'bo',alpha=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_lengths = load_array(path.join(raw_path, 'simul_Length.npy'))\n",
    "Lambda_ij = load_array(path.join(raw_path,'simul_Lambda_ij.npy'))\n",
    "# assert Lambda_ij.shape[1]!=edges.shape[0]\n",
    "\n",
    "A0 = load_array(path.join(raw_path, 'simul_A0.npy'))\n",
    "Area = load_array(path.join(raw_path, 'simul_Area.npy'))\n",
    "Ka = load_array(path.join(raw_path, 'simul_Ka.npy'))\n",
    "\n",
    "P0 = load_array(path.join(raw_path, 'simul_P0.npy'))\n",
    "Perims = load_array(path.join(raw_path, 'simul_Perimeter.npy'))\n",
    "Kp = load_array(path.join(raw_path, 'simul_Kp.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$T_{edge:(i,j)} = \\Lambda_{ij}(t)+\\sum_{k\\in\\{cells\\ for\\ (i,j)\\}}K_p^{(k)}(p^{(k)}-p_0^{(k)})$$\n",
    "$$\\pi_{cell:k} = -2K_a^{(k)}(a^{(k)}-a_0^{(k)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_lengths.max()\n",
    "# plt.hist(Perims.ravel(),bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(Area.ravel(),bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist((edge_lengths.ravel()), bins=50, density=True);\n",
    "# plt.xlabel('Edge Lengths (a.u.)')\n",
    "# plt.ylabel('Frequency (normalised)')\n",
    "# plt.title('10x10 cell monolayer trial with random oscillations\\n(17-Nov-2020; 100 sample frames from a movie)')\n",
    "# plt.savefig('edge_length_17Nov2020.png',dpi=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# np.random.seed(42)\n",
    "\n",
    "# cell_samples = np.random.choice(list(mg_dict['cells'].keys()),10)\n",
    "\n",
    "# mg_nx = nx.Graph(mg_dict['edges'])\n",
    "# nx.draw(mg_nx,pos=dict(zip(range(vx0.shape[0]),vx0)),\n",
    "#         node_size=20,width=4,node_color='#FF00FF',edge_color='#51C5FF')\n",
    "# for c in cell_samples:\n",
    "#     c_vxs = vx0[edges[(np.abs(mg_dict['cells'][c])-1)].view(-1,),:]\n",
    "#     c_loc = c_vxs.mean(axis=0)\n",
    "#     plt.plot(c_loc[0],c_loc[1],'ro',ms=10)\n",
    "#     for vx_i in c_vxs:\n",
    "#         plt.plot([vx_i[0],c_loc[0]], [vx_i[1],c_loc[1]],lw=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with PyTorch Geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Node features** : velocities from previous frames (~ 5 frames--> Alvaro Sanchez-Gonzalez, *et al.* 2020 \\[ASG2020\\])\n",
    "- **Edge features** : can use edge directions (optional, might help to speed up training)\n",
    "- **Current position** : technically a node feature, and needs to be normalized but not processed by the network.\n",
    "- Positions (Cartesian) to polar edge attributes: `transforms.Polar` \\[[link](https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.Polar)\\], I can also implement or use the `transforms.Cartesian` which computes direction vectors (position pairs -to- normalized direction vectors).\n",
    "- need transform for velocity noise (use src from example transforms above and ASG2020 paper)\n",
    "- Trail movie: max edge length ~ 3.25 a.u."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch_geometric.data.Data` attributes:\n",
    "- `.x` : node features `[num_nodes, num_node_features]`\n",
    "- `.edge_index` : edges as \\[source, target\\] node index pairs (COO format) with shape `[2, num_edges]` and `torch.long` type (int).\n",
    "- `.edge_attr`: edge features with shape `[num_edges, num_edge_features]`\n",
    "- `.y` : target, arbitrary shape, if node-level target then `[num_nodes, *]`, or graph-level target `[1, *]`\n",
    "- `.pos`: node positions `[num_nodes, num_dims]`.\n",
    "- can add additional attributes, e.g. \"cells\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.utils import to_networkx, from_networkx\n",
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simgnn.datasets import VertexDynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare computed and original *edge lengths*\n",
    "# dist_fn = T.Distance(norm=False)\n",
    "# compute cartesian distances\n",
    "# dist_fn(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VertexDynamics(95)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtxdata = VertexDynamics('../../../dataDIR/simgnn_data')\n",
    "vtxdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t=5\n",
    "# Dt = 1\n",
    "# # plt.figure(figsize=[25,25])\n",
    "# nx.draw(to_networkx(vtxdata[t], to_undirected=True),pos=dict(enumerate(vtxdata[t].pos.numpy())), node_size=60)\n",
    "# nx.draw(to_networkx(vtxdata[t+Dt], to_undirected=True),pos=dict(enumerate(vtxdata[t+Dt].pos.numpy())),\n",
    "#         node_size=20,width=4,\n",
    "#         node_color='#FF00FF',edge_color='#51C5FF',alpha=.5)\n",
    "# plt.quiver(vtxdata[t].pos.numpy()[:,0], vtxdata[t].pos.numpy()[:,1],\n",
    "#            vtxdata[t].y.numpy()[:,0],vtxdata[t].y.numpy()[:,1],\n",
    "#            units='xy',angles='xy',scale=.25,color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(vtxdata[10, 20], batch_size=2)\n",
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellData(Data):\n",
    "    '''Cell monolayer graph data'''\n",
    "    def __init__(self, y_cell=None, num_cells=None,\n",
    "                 node2cell_index=None, cell2node_index=None, **kwargs):\n",
    "        super(CellData, self).__init__(**kwargs)\n",
    "        self.node2cell_index = node2cell_index\n",
    "        self.cell2node_index = cell2node_index\n",
    "        self.y_cell = y_cell\n",
    "        self.num_cells_ = num_cells\n",
    "    \n",
    "    @property\n",
    "    def num_cells(self):\n",
    "        if self.num_cells_!=None:\n",
    "            return self.num_cells_\n",
    "        if self.node2cell_index!=None:\n",
    "            print('Number of cells is inferred from `node2cell_index`!')\n",
    "            return self.node2cell_index[1].max()+1\n",
    "        if self.cell2node_index!=None:\n",
    "            print('Number of cells is inferred from `cell2node_index`!')\n",
    "            return self.cell2node_index[0].max()+1\n",
    "    \n",
    "    @num_cells.setter\n",
    "    def num_cells(self,val):\n",
    "        self.num_cells_ = val\n",
    "        \n",
    "    def __inc__(self, key, value):\n",
    "        if key == 'node2cell_index':\n",
    "            return torch.tensor([[self.num_nodes], [self.num_cells]])\n",
    "        if key == 'cell2node_index':\n",
    "            return torch.tensor([[self.num_cells], [self.num_nodes]])\n",
    "        else:\n",
    "            return super(CellData, self).__inc__(key, value)\n",
    "    \n",
    "    def __cat_dim__(self, key, value):\n",
    "        if key == 'node2cell_index' or key == 'cell2node_index':\n",
    "            return 1\n",
    "        else:\n",
    "            return super(CellData, self).__cat_dim__(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=CellData(node2cell_index=torch.tensor([[1,2],[10,11]]),pos=torch.tensor([.1,.3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CellData(node2cell_index=[2, 2], pos=[2])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#datasets: 1 \n",
      "1st: Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708]) \n",
      "Name: Cora()\n",
      "Training 2-layer GCN.\n",
      "Epoch    39| Accuracy: 78.30% |\n",
      "Epoch    79| Accuracy: 79.60% |\n",
      "Epoch   119| Accuracy: 79.30% |\n",
      "Epoch   159| Accuracy: 79.50% |\n",
      "Epoch   199| Accuracy: 80.40% |\n",
      "Accuracy: 0.8040\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "print('#datasets:',len(dataset),'\\n1st:',dataset[0],'\\nName:',dataset)\n",
    "\n",
    "# 2-layer GCN\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "print('Training 2-layer GCN.')\n",
    "tot_epoch = 200\n",
    "print_freq = tot_epoch//5\n",
    "for epoch in range(tot_epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1)%print_freq==0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, pred = model(data).max(dim=1)\n",
    "            correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "            print('Epoch {:5}| Accuracy: {:4.2f}% |'.format(epoch,100*correct / int(data.test_mask.sum())))\n",
    "\n",
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / int(data.test_mask.sum())\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
