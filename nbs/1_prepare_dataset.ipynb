{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Dataset Loading and Batching\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from os import path\n",
    "\n",
    "import networkx as nx\n",
    "from simgnn.datautils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10,10) # use larger for presentation\n",
    "matplotlib.rcParams['font.size']= 14 # use 14 for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deafults:\n",
      " |-device: cuda\n",
      " |-dtype : torch.float32\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "dtype = torch.float32\n",
    "print(f'Deafults:\\n |-device: {device}\\n |-dtype : {dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '../../../dataDIR/simgnn_data/raw'# location of all datasets\n",
    "data_path = path.join(data_root,'17Nov2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_dict.pkl\tsimul_Ka.npy\t     simul_Length.npy\t  simul_t.npy\n",
      "simul_A0.npy\tsimul_Kp.npy\t     simul_P0.npy\t  simul_vtxpos.npy\n",
      "simul_Area.npy\tsimul_Lambda_ij.npy  simul_Perimeter.npy  t_Energy_maxSpeed.npy\n"
     ]
    }
   ],
   "source": [
    "!ls $data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representation of cells in the monolayer graph:\n",
    "- dict of lists with cell numbers $0, 1, \\dots N$ as keys, and edges (values).\n",
    "- edge ind-s **start from 1** in the cells (values), don't forget to **convert** when indexing edges tensor (e.g. `edge_ID=np.abs(ID)-1`). Negative indices indicate reversed order for vertices (cell is defined as a closed region formed by edges connected *end-to-end*). Use `np.sign(cells[c])` to find reversed edges for cell `c`.\n",
    "    - e.g. get edges of cell `c` : `np.abs(mg_dict['cells'][c])-1` (`mg_dict` is monolayer graph dict loaded with `datautils.load_graph`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dict of monolayer graph\n",
    "mg_dict = load_graph(path.join(data_path,'graph_dict.pkl'))\n",
    "\n",
    "# Load vertex positions from simulation results: Frames x Vertices x Positions\n",
    "vx_pos = load_array(path.join(data_path,'simul_vtxpos.npy'))\n",
    "\n",
    "# init-l vertex positions (1st frame)\n",
    "vx0 = vx_pos[0]\n",
    "\n",
    "# convert edges list to tensor\n",
    "edges = torch.tensor(mg_dict['edges'],dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_lengths = load_array(path.join(data_path, 'simul_Length.npy'))\n",
    "Lambda_ij = load_array(path.join(data_path,'simul_Lambda_ij.npy'))\n",
    "# assert Lambda_ij.shape[1]!=edges.shape[0]\n",
    "\n",
    "A0 = load_array(path.join(data_path, 'simul_A0.npy'))\n",
    "Area = load_array(path.join(data_path, 'simul_Area.npy'))\n",
    "Ka = load_array(path.join(data_path, 'simul_Ka.npy'))\n",
    "\n",
    "P0 = load_array(path.join(data_path, 'simul_P0.npy'))\n",
    "Perims = load_array(path.join(data_path, 'simul_Perimeter.npy'))\n",
    "Kp = load_array(path.join(data_path, 'simul_Kp.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_lengths.max()\n",
    "# plt.hist(Perims.ravel(),bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(Area.ravel(),bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist((edge_lengths.ravel()), bins=50, density=True);\n",
    "# plt.xlabel('Edge Lengths (a.u.)')\n",
    "# plt.ylabel('Frequency (normalised)')\n",
    "# plt.title('10x10 cell monolayer trial with random oscillations\\n(17-Nov-2020; 100 sample frames from a movie)')\n",
    "# plt.savefig('edge_length_17Nov2020.png',dpi=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# np.random.seed(42)\n",
    "\n",
    "# cell_samples = np.random.choice(list(mg_dict['cells'].keys()),10)\n",
    "\n",
    "# mg_nx = nx.Graph(mg_dict['edges'])\n",
    "# nx.draw(mg_nx,pos=dict(zip(range(vx0.shape[0]),vx0)),\n",
    "#         node_size=20,width=4,node_color='#FF00FF',edge_color='#51C5FF')\n",
    "# for c in cell_samples:\n",
    "#     c_vxs = vx0[edges[(np.abs(mg_dict['cells'][c])-1)].view(-1,),:]\n",
    "#     c_loc = c_vxs.mean(axis=0)\n",
    "#     plt.plot(c_loc[0],c_loc[1],'ro',ms=10)\n",
    "#     for vx_i in c_vxs:\n",
    "#         plt.plot([vx_i[0],c_loc[0]], [vx_i[1],c_loc[1]],lw=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with PyTorch Geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch_geometric.data.Data` attributes:\n",
    "- `.x` : node features `[num_nodes, num_node_features]`\n",
    "- `.edge_index` : edges as \\[source, target\\] node index pairs (COO format) with shape `[2, num_edges]` and `torch.long` type (int).\n",
    "- `.edge_attr`: edge features with shape `[num_edges, num_edge_features]`\n",
    "- `.y` : target, arbitrary shape, if node-level target then `[num_nodes, *]`, or graph-level target `[1, *]`\n",
    "- `.pos`: node positions `[num_nodes, num_dims]`.\n",
    "- can add additional attributes, e.g. \"cells\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data()\n",
    "data.num_nodes = vx0.shape[0]\n",
    "# undirected graph {ij, ji} pairs\n",
    "data.edge_index =  torch.cat( [edges.T.contiguous(), edges.fliplr().T.contiguous()], axis=1)\n",
    "data.pos = torch.from_numpy(vx0).type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_dict.pkl\tsimul_Ka.npy\t     simul_Length.npy\t  simul_t.npy\n",
      "simul_A0.npy\tsimul_Kp.npy\t     simul_P0.npy\t  simul_vtxpos.npy\n",
      "simul_Area.npy\tsimul_Lambda_ij.npy  simul_Perimeter.npy  t_Energy_maxSpeed.npy\n"
     ]
    }
   ],
   "source": [
    "!ls $data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 21,  22,   3,  ..., 235, 232, 238],\n",
       "        [ 22,   3,   2,  ..., 210, 239, 233]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Node features** : velocities from previous frames (~ 5 frames--> Alvaro Sanchez-Gonzalez, *et al.* 2020 \\[ASG2020\\])\n",
    "- **Edge features** : can use edge directions (optional, might help to speed up training)\n",
    "- **Current position** : technically a node feature, and needs to be normalized but not processed by the network.\n",
    "- Positions (Cartesian) to polar edge attributes: `transforms.Polar` \\[[link](https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.Polar)\\], I can also implement or use the `transforms.Cartesian` which computes direction vectors (position pairs -to- normalized direction vectors).\n",
    "- need transform for velocity noise (use src from example transforms above and ASG2020 paper)\n",
    "- Trail movie: max edge length ~ 3.25 a.u."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['edge_index', 'pos']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare computed and original *edge lengths*\n",
    "# dist_fn = T.Distance(norm=False)\n",
    "# compute cartesian distances\n",
    "# dist_fn(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset\n",
    "from os import path, listdir\n",
    "\n",
    "class VertexDynamics(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        '''\n",
    "        Assumes `root` dir contains folder named `raw` with all vertex dynamics simulation results\n",
    "        for tracing vertex trajectories, building graphs, and variables for computing edge tensions \n",
    "        and cell pressures.\n",
    "        \n",
    "        Arg-s:\n",
    "        - root : path to a root directory that contains folder with raw dataset(s) in a folder named \"raw\".\n",
    "        Raw datasets should be placed into separate folders each containing a separate simulation results.\n",
    "        E.g. root contains [\"raw\", \"processed\", ...], and in folder \"raw/\" we should have [\"simul1\", \"simul2\", ...]\n",
    "        - transform :  transform(s) for graph datasets (e.g. from torch_geometric.transforms )\n",
    "        - pre_transform : transform(s) for data pre-processing (resulting graphs are saved in \"preprocessed\" folder)\n",
    "        and used as this dataset's sample graphs.\n",
    "        '''\n",
    "        super(VertexDynamics, self).__init__(root, transform, pre_transform)\n",
    "        \n",
    "        self.raw_dir_path = path.join(self.root,'raw')\n",
    "        assert path.isdir(self.raw_dir_path), f'Folder \"{self.root}\" does not contain folder named \"raw\".'\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        raw_dirs = [folder_i for folder_i in listdir(self.raw_dir_path) \n",
    "                    if path.isdir( path.join( self.raw_dir_path, folder_i))]\n",
    "        file_names = [path.join(dir_i, file_i) for dir_i in raw_dirs\n",
    "                      for file_i in listdir(path.join(self.raw_dir_path,dir_i))] \n",
    "        return file_names\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        #self.processed_dir # root/processed_dir\n",
    "        return []#['data_1.pt', 'data_2.pt', ...]\n",
    "\n",
    "    def process(self):\n",
    "        pass\n",
    "#         i = 0\n",
    "#         for raw_path in self.raw_paths:\n",
    "#             # Read data from `raw_path`.\n",
    "#             data = Data(...)\n",
    "\n",
    "#             if self.pre_filter is not None and not self.pre_filter(data):\n",
    "#                 continue\n",
    "\n",
    "#             if self.pre_transform is not None:\n",
    "#                 data = self.pre_transform(data)\n",
    "\n",
    "#             torch.save(data, osp.join(self.processed_dir, 'data_{}.pt'.format(i)))\n",
    "#             i += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        pass\n",
    "        #data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(idx)))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VertexDynamics(0)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtxdata = VertexDynamics('../../../dataDIR/simgnn_data')\n",
    "vtxdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../../dataDIR/simgnn_data/processed'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtxdata.processed_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#datasets: 1 \n",
      "1st: Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708]) \n",
      "Name: Cora()\n",
      "Training 2-layer GCN.\n",
      "Epoch    39| Accuracy: 78.30% |\n",
      "Epoch    79| Accuracy: 79.60% |\n",
      "Epoch   119| Accuracy: 79.30% |\n",
      "Epoch   159| Accuracy: 79.50% |\n",
      "Epoch   199| Accuracy: 80.40% |\n",
      "Accuracy: 0.8040\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "print('#datasets:',len(dataset),'\\n1st:',dataset[0],'\\nName:',dataset)\n",
    "\n",
    "# 2-layer GCN\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "print('Training 2-layer GCN.')\n",
    "tot_epoch = 200\n",
    "print_freq = tot_epoch//5\n",
    "for epoch in range(tot_epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1)%print_freq==0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, pred = model(data).max(dim=1)\n",
    "            correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "            print('Epoch {:5}| Accuracy: {:4.2f}% |'.format(epoch,100*correct / int(data.test_mask.sum())))\n",
    "\n",
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / int(data.test_mask.sum())\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
