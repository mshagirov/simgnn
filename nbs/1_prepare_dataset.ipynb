{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Dataset Loading and Batching\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from os import path\n",
    "\n",
    "import networkx as nx\n",
    "from simgnn.datautils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10,10) # use larger for presentation\n",
    "matplotlib.rcParams['font.size']= 14 # use 14 for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaults:\n",
      " |-device: cuda\n",
      " |-dtype : torch.float32\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "dtype = torch.float32\n",
    "print(f'Defaults:\\n |-device: {device}\\n |-dtype : {dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Need to implement*: `raw_i` $\\mapsto$ `Data()`$\\mapsto$ `Dataset.process()` $\\mapsto$`processed` dir (save processed graphs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '../../../dataDIR/simgnn_data/raw'# location of all datasets\n",
    "raw_path = path.join(data_root,'17Nov2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_dict.pkl\tsimul_Ka.npy\t     simul_Length.npy\t  simul_t.npy\n",
      "simul_A0.npy\tsimul_Kp.npy\t     simul_P0.npy\t  simul_vtxpos.npy\n",
      "simul_Area.npy\tsimul_Lambda_ij.npy  simul_Perimeter.npy  t_Energy_maxSpeed.npy\n"
     ]
    }
   ],
   "source": [
    "!ls $raw_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representation of cells in the monolayer graph:\n",
    "- dict of lists with cell numbers $0, 1, \\dots N$ as keys, and edges (values).\n",
    "- edge ind-s **start from 1** in the cells (values), don't forget to **convert** when indexing edges tensor (e.g. `edge_ID=np.abs(ID)-1`). Negative indices indicate reversed order for vertices (cell is defined as a closed region formed by edges connected *end-to-end*). Use `np.sign(cells[c])` to find reversed edges for cell `c`.\n",
    "    - e.g. get edges of cell `c` : `np.abs(mg_dict['cells'][c])-1` (`mg_dict` is monolayer graph dict loaded with `datautils.load_graph`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dict of monolayer graph\n",
    "mg_dict = load_graph(path.join(raw_path,'graph_dict.pkl'))\n",
    "\n",
    "# Load vertex positions from simulation results: Frames x Vertices x Positions\n",
    "vx_pos = load_array(path.join(raw_path,'simul_vtxpos.npy')) # T x N x 2\n",
    "vx_vel = np.diff(vx_pos,n=1,axis=0) # T-1 x N x 2\n",
    "\n",
    "# init-l vertex positions (1st frame)\n",
    "vx0 = vx_pos[0]\n",
    "\n",
    "# convert edges list to tensor\n",
    "edges = torch.tensor(mg_dict['edges'],dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_pos:(95, 240, 2) (T+0 pos-n)\n",
      "node_features:(95, 240, 5, 2) ([T-1:T-window_size] vel-s)\n",
      "- - - - - - -\n",
      "Y_node : (95, 240, 2) (T+0 vel-y)\n"
     ]
    }
   ],
   "source": [
    "window_size = 5\n",
    "Y_node = vx_vel[window_size:] # Vel[w:]\n",
    "node_pos = vx_pos[window_size:-1]\n",
    "\n",
    "# last_index = total_frames - (2+window_size)\n",
    "# num_of_features = last_index+1\n",
    "X_node = np.stack([ vx_vel[k:k+window_size].transpose((1,0,2))\n",
    "                    for k in range(vx_pos.shape[0]-(2+window_size)+1)])\n",
    "\n",
    "print(f'node_pos:{node_pos.shape} (T+0 pos-n)')\n",
    "print(f'node_features:{X_node.shape} ([T-1:T-window_size] vel-s)\\n-'+5*' -'+' -')\n",
    "print(f'Y_node : {Y_node.shape} (T+0 vel-y)')\n",
    "# node_pos[0] = vx_pos[window_size] ; node_pos[-1] = vx_pos[-2]\n",
    "# =>vx_pos[-1]=node_pos[-1]+Y_node[-1]\n",
    "# node_next = vx_pos[window_size+1:]\n",
    "# assert np.sum(np.abs(Y_node+node_pos-node_next)) == 0\n",
    "#\n",
    "# assert np.sum(np.abs(X_node[0][:,-1,:]-vx_vel[4])) ==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = 13\n",
    "# plt.quiver(vx_pos[t,:,0],vx_pos[t,:,1], vx_vel[t,:,0], vx_vel[t,:,1],units='xy',angles='xy',scale=.1)\n",
    "# plt.plot(vx_pos[t,:,0],vx_pos[t,:,1],'ro',alpha=.5)\n",
    "# plt.plot(vx_pos[t+1,:,0],vx_pos[t+1,:,1],'bo',alpha=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_lengths = load_array(path.join(raw_path, 'simul_Length.npy'))\n",
    "Lambda_ij = load_array(path.join(raw_path,'simul_Lambda_ij.npy'))\n",
    "# assert Lambda_ij.shape[1]!=edges.shape[0]\n",
    "\n",
    "A0 = load_array(path.join(raw_path, 'simul_A0.npy'))\n",
    "Area = load_array(path.join(raw_path, 'simul_Area.npy'))\n",
    "Ka = load_array(path.join(raw_path, 'simul_Ka.npy'))\n",
    "\n",
    "P0 = load_array(path.join(raw_path, 'simul_P0.npy'))\n",
    "Perims = load_array(path.join(raw_path, 'simul_Perimeter.npy'))\n",
    "Kp = load_array(path.join(raw_path, 'simul_Kp.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$T_{edge:(i,j)} = \\Lambda_{ij}(t)+\\sum_{k\\in\\{cells\\ for\\ (i,j)\\}}K_p^{(k)}(p^{(k)}-p_0^{(k)})$$\n",
    "$$\\pi_{cell:k} = -2K_a^{(k)}(a^{(k)}-a_0^{(k)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_lengths.max()\n",
    "# plt.hist(Perims.ravel(),bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(Area.ravel(),bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist((edge_lengths.ravel()), bins=50, density=True);\n",
    "# plt.xlabel('Edge Lengths (a.u.)')\n",
    "# plt.ylabel('Frequency (normalised)')\n",
    "# plt.title('10x10 cell monolayer trial with random oscillations\\n(17-Nov-2020; 100 sample frames from a movie)')\n",
    "# plt.savefig('edge_length_17Nov2020.png',dpi=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# np.random.seed(42)\n",
    "\n",
    "# cell_samples = np.random.choice(list(mg_dict['cells'].keys()),10)\n",
    "\n",
    "# mg_nx = nx.Graph(mg_dict['edges'])\n",
    "# nx.draw(mg_nx,pos=dict(zip(range(vx0.shape[0]),vx0)),\n",
    "#         node_size=20,width=4,node_color='#FF00FF',edge_color='#51C5FF')\n",
    "# for c in cell_samples:\n",
    "#     c_vxs = vx0[edges[(np.abs(mg_dict['cells'][c])-1)].view(-1,),:]\n",
    "#     c_loc = c_vxs.mean(axis=0)\n",
    "#     plt.plot(c_loc[0],c_loc[1],'ro',ms=10)\n",
    "#     for vx_i in c_vxs:\n",
    "#         plt.plot([vx_i[0],c_loc[0]], [vx_i[1],c_loc[1]],lw=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with PyTorch Geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch_geometric.data.Data` attributes:\n",
    "- `.x` : node features `[num_nodes, num_node_features]`\n",
    "- `.edge_index` : edges as \\[source, target\\] node index pairs (COO format) with shape `[2, num_edges]` and `torch.long` type (int).\n",
    "- `.edge_attr`: edge features with shape `[num_edges, num_edge_features]`\n",
    "- `.y` : target, arbitrary shape, if node-level target then `[num_nodes, *]`, or graph-level target `[1, *]`\n",
    "- `.pos`: node positions `[num_nodes, num_dims]`.\n",
    "- can add additional attributes, e.g. \"cells\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data()\n",
    "data.num_nodes = vx0.shape[0]\n",
    "# undirected graph {ij, ji} pairs\n",
    "data.edge_index =  torch.cat( [edges.T.contiguous(), edges.fliplr().T.contiguous()], axis=1)\n",
    "data.pos = torch.from_numpy(vx0).type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_dict.pkl\tsimul_Ka.npy\t     simul_Length.npy\t  simul_t.npy\n",
      "simul_A0.npy\tsimul_Kp.npy\t     simul_P0.npy\t  simul_vtxpos.npy\n",
      "simul_Area.npy\tsimul_Lambda_ij.npy  simul_Perimeter.npy  t_Energy_maxSpeed.npy\n"
     ]
    }
   ],
   "source": [
    "!ls $data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 21,  22,   3,  ..., 235, 232, 238],\n",
       "        [ 22,   3,   2,  ..., 210, 239, 233]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Node features** : velocities from previous frames (~ 5 frames--> Alvaro Sanchez-Gonzalez, *et al.* 2020 \\[ASG2020\\])\n",
    "- **Edge features** : can use edge directions (optional, might help to speed up training)\n",
    "- **Current position** : technically a node feature, and needs to be normalized but not processed by the network.\n",
    "- Positions (Cartesian) to polar edge attributes: `transforms.Polar` \\[[link](https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.Polar)\\], I can also implement or use the `transforms.Cartesian` which computes direction vectors (position pairs -to- normalized direction vectors).\n",
    "- need transform for velocity noise (use src from example transforms above and ASG2020 paper)\n",
    "- Trail movie: max edge length ~ 3.25 a.u."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['edge_index', 'pos']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare computed and original *edge lengths*\n",
    "# dist_fn = T.Distance(norm=False)\n",
    "# compute cartesian distances\n",
    "# dist_fn(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile graph(s) into a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, listdir\n",
    "from glob import glob\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from simgnn.datautils import *\n",
    "\n",
    "class VertexDynamics(Dataset):\n",
    "    def __init__(self, root, window_size=5, transform=None, pre_transform=None):\n",
    "        '''\n",
    "        Assumes `root` dir contains folder named `raw` with all vertex dynamics simulation results\n",
    "        for tracing vertex trajectories, building graphs, and variables for computing edge tensions \n",
    "        and cell pressures.\n",
    "        - Velocities are approximated as 1st order differences of positions `x` in subsequent frames:\n",
    "          `velocity(T+0) = x(T+1) - x(T+0)`.\n",
    "        - Use `pre_transform` for normalising and pre-processing dataset(s).\n",
    "        \n",
    "        Arg-s:\n",
    "        - root : path to a root directory that contains folder with raw dataset(s) in a folder named \"raw\".\n",
    "        Raw datasets should be placed into separate folders each containing outputs from a single simulation.\n",
    "        E.g. root contains [\"raw\", \"processed\", ...], and in folder \"raw/\" we should have [\"simul1\", \"simul2\", ...]\n",
    "        - window_size : number of past velocities to be used as node features \n",
    "        `[x(T+0)-x(T-1), x(T-1)-x(T-2),..., x(T-window_size+1)-x(T-window_size)]`, where `x(T)` is node position at time `T`.\n",
    "        - transform :  transform(s) for graph datasets (e.g. from torch_geometric.transforms )\n",
    "        - pre_transform : transform(s) for data pre-processing (resulting graphs are saved in \"preprocessed\" folder)\n",
    "        and used as this dataset's sample graphs.\n",
    "        '''\n",
    "        super(VertexDynamics, self).__init__(root, transform, pre_transform)\n",
    "        # super's __init__ runs process() [and download() if defined].\n",
    "        \n",
    "        self.raw_dir_path = path.join(self.root,'raw')\n",
    "        assert path.isdir(self.raw_dir_path), f'Folder \"{self.root}\" does not contain folder named \"raw\".'\n",
    "        \n",
    "        self.window_size = window_size\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        raw_dirs = [folder_i for folder_i in listdir(self.raw_dir_path) \n",
    "                    if path.isdir( path.join( self.raw_dir_path, folder_i))]\n",
    "        #file_names = [path.join(dir_i, file_i) for dir_i in raw_dirs\n",
    "        #              for file_i in listdir(path.join(self.raw_dir_path,dir_i))] \n",
    "        return raw_dirs\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        '''Return list of `data_*.pt` files in `root/processed` folder.'''\n",
    "        if not path.isdir(self.processed_dir):\n",
    "            return []\n",
    "        # root/processed_dir == self.processed_dir \n",
    "        # should contain pytorch-geometric graphs, e.g. ['data_1.pt', 'data_2.pt', ...]\n",
    "        return glob(path.join(self.processed_dir,'data_*.pt'))\n",
    "\n",
    "    def process(self):\n",
    "        '''\n",
    "        Assumes that the parent class init runs _process() and initialises all the required dir-s.\n",
    "        '''\n",
    "        i = 0 # graph counter\n",
    "        for raw_path in self.raw_paths:\n",
    "            # simulation instance in \"raw_path\"\n",
    "            # \"window_size\": number of previous velocities (node features)\n",
    "            # \"last_idx\" : last index of window in vx_vel (for features)\n",
    "            # last_idx=T-(2+window_size) --> num_of_frames=last_idx+1 \n",
    "            \n",
    "            # vertex trajectories:(Frames,Vertices,Dims)=TxNx2\n",
    "            vx_pos = load_array(path.join(raw_path,'simul_vtxpos.npy')) #TxNx2\n",
    "            vx_vel = np.diff(vx_pos,n=1,axis=0) # velocity(1st diff approx):(T-1)xNx2\n",
    "            \n",
    "            # T+0 vertex positions\n",
    "            node_pos = vx_pos[self.window_size:-1] # (num_of_frames)xNx2\n",
    "            \n",
    "            # T-1 to T-window_size velocities : (num_of_frames)xNx(window_size)x2\n",
    "            X_node = np.stack([ vx_vel[k:k+self.window_size].transpose((1,0,2))\n",
    "                                for k in range(vx_pos.shape[0]-(2+self.window_size)+1)])\n",
    "            \n",
    "            # T+0 vertex velocities\n",
    "            Y_node = vx_vel[self.window_size:] # (num_of_frames)xNx2\n",
    "            \n",
    "            # monolayer graph (topology)\n",
    "            mg_dict = load_graph(path.join(raw_path,'graph_dict.pkl'))\n",
    "            edges = torch.tensor(mg_dict['edges'],dtype=torch.long)\n",
    "            \n",
    "#             # Read data from `raw_path`.\n",
    "#             data = Data(...)\n",
    "\n",
    "#             if self.pre_filter is not None and not self.pre_filter(data):\n",
    "#                 continue\n",
    "\n",
    "#             if self.pre_transform is not None:\n",
    "#                 data = self.pre_transform(data)\n",
    "\n",
    "#             torch.save(data, osp.join(self.processed_dir, 'data_{}.pt'.format(i)))\n",
    "            i += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        pass\n",
    "        #data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(idx)))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VertexDynamics(0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtxdata = VertexDynamics('../../../dataDIR/simgnn_data')\n",
    "vtxdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtxdata.processed_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../dataDIR/simgnn_data/raw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../../dataDIR/simgnn_data/raw/17Nov2020']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vtxdata.raw_dir)\n",
    "vtxdata.raw_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_dict.pkl\tsimul_Ka.npy\t     simul_Length.npy\t  simul_t.npy\n",
      "simul_A0.npy\tsimul_Kp.npy\t     simul_P0.npy\t  simul_vtxpos.npy\n",
      "simul_Area.npy\tsimul_Lambda_ij.npy  simul_Perimeter.npy  t_Energy_maxSpeed.npy\n"
     ]
    }
   ],
   "source": [
    "!ls {' '.join(vtxdata.raw_paths)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#datasets: 1 \n",
      "1st: Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708]) \n",
      "Name: Cora()\n",
      "Training 2-layer GCN.\n",
      "Epoch    39| Accuracy: 78.30% |\n",
      "Epoch    79| Accuracy: 79.60% |\n",
      "Epoch   119| Accuracy: 79.30% |\n",
      "Epoch   159| Accuracy: 79.50% |\n",
      "Epoch   199| Accuracy: 80.40% |\n",
      "Accuracy: 0.8040\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "print('#datasets:',len(dataset),'\\n1st:',dataset[0],'\\nName:',dataset)\n",
    "\n",
    "# 2-layer GCN\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "print('Training 2-layer GCN.')\n",
    "tot_epoch = 200\n",
    "print_freq = tot_epoch//5\n",
    "for epoch in range(tot_epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1)%print_freq==0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, pred = model(data).max(dim=1)\n",
    "            correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "            print('Epoch {:5}| Accuracy: {:4.2f}% |'.format(epoch,100*correct / int(data.test_mask.sum())))\n",
    "\n",
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / int(data.test_mask.sum())\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
